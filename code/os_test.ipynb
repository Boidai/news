{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def get_line_url(url):\n",
    "    line_url = os.popen(\"\"\"curl -XPOST \\\n",
    "    -H \"Authorization: Bearer token\" \\\n",
    "    -H \"Content-Type: application/json\" \\\n",
    "    -d '{\n",
    "        \"view\": {\n",
    "            \"type\": \"tall\",\n",
    "            \"url\": \" '%s' \"\n",
    "        }\n",
    "    }' \\\n",
    "    https://api.line.me/liff/v1/apps\"\"\" % (url)) \n",
    "\n",
    "    my_link = \"line://app/\"+json.loads(line_url.read())['liffId']\n",
    "    line_url.close\n",
    "    return my_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "if_end = True\n",
    "store_datetime = datetime.datetime.now().strftime(\"%Y/%m/%d\")\n",
    "my_json = []\n",
    "for page in range(1, 12):\n",
    "    if if_end == False:\n",
    "        break\n",
    "    href = \"https://tw.news.appledaily.com/politics/realtime/\"+ str(page)\n",
    "    res = requests.get(href)\n",
    "    html = BeautifulSoup(res.text)\n",
    "    all_news_1 = html.find_all(\"ul\", class_=\"rtddd slvl\")\n",
    "    for all_news in all_news_1:\n",
    "        if if_end == False:\n",
    "            break\n",
    "        news = all_news.find_all(\"a\")\n",
    "        for n in news:\n",
    "            my_news = {}\n",
    "            news_url =\"https://tw.news.appledaily.com/\" + str(n[\"href\"])\n",
    "            news_per = requests.get(news_url)\n",
    "            bs = BeautifulSoup(news_per.text)\n",
    "\n",
    "            if bs.find(\"div\", class_=\"ndArticle_view\") == None:\n",
    "                views = 0\n",
    "            else:\n",
    "                views = int(bs.find(\"div\", class_=\"ndArticle_view\").text)\n",
    "            date_time = bs.find(\"div\", class_=\"ndArticle_creat\").text.replace(\"出版時間：\", \"\").split(\" \")[0]\n",
    "            if not date_time == store_datetime:\n",
    "                if_end = False\n",
    "                break\n",
    "            my_news= {\"url\": news_url, \"views\": views}\n",
    "            my_json.append(my_news)\n",
    "            print(my_news)\n",
    "\n",
    "sorted_json = sorted(my_json ,key = lambda my_json:my_json['views'], reverse = True)\n",
    "\n",
    "select * from chatbot_db.News where release_datetime = curdate();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
